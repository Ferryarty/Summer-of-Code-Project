{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_analysis=pd.read_csv(\"Consumer_Dataset.csv\")\n",
    "consumer_test_data=pd.read_csv(\"Consumer Test Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The following cell drops the rows which are duplicate or contains NA values. This is done to make sure that these rows doesn't hinder with the learning of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6665 entries, 0 to 6664\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           6665 non-null   int64  \n",
      " 1   Gender               6665 non-null   object \n",
      " 2   Age                  6665 non-null   int64  \n",
      " 3   Ever_Married         6665 non-null   object \n",
      " 4   Family_Size          6665 non-null   float64\n",
      " 5   Profession           6665 non-null   object \n",
      " 6   Graduated            6665 non-null   object \n",
      " 7   Work_Experience      6665 non-null   float64\n",
      " 8   Energy_Consumption   6665 non-null   object \n",
      " 9   Preferred_Renewable  6665 non-null   object \n",
      " 10  Group                6665 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 572.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "consumer_analysis=consumer_analysis.dropna().reset_index(drop=True)\n",
    "consumer_analysis.drop_duplicates(inplace=True)\n",
    "print(consumer_analysis.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The following cell contains the feature vector creation. The non numeric values are change to 0 or 1 by making a new row for each non-numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[ \"Male\" , \"Female\", \"Age\", \"Ever_Married\", \"Family_Size\"]\n",
    "\n",
    "for i in consumer_analysis[\"Profession\"]:\n",
    "    if i in feature:\n",
    "        continue\n",
    "    else:\n",
    "        feature.append(i)\n",
    "feature.extend([\"Graduated\", \"Work_Experience\"])\n",
    "for i in consumer_analysis[\"Energy_Consumption\"]:\n",
    "    if i in feature:\n",
    "        continue\n",
    "    else:\n",
    "        feature.append(i)\n",
    "for i in consumer_analysis[\"Preferred_Renewable\"]:\n",
    "    if i in feature:\n",
    "        continue\n",
    "    else:\n",
    "        feature.append(i)\n",
    "feature_vector=pd.DataFrame(feature)\n",
    "feature_vector.rename(columns={0:\"Features\"}, inplace=True)\n",
    "feature_vector[\"Values\"]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "In the following cell I have made the function for obtaining the feature vector and the group label for each data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phix(i):\n",
    "    phi=feature_vector.copy()\n",
    "    if(consumer_analysis.loc[i, \"Gender\"]==\"Male\"):\n",
    "        phi.loc[0,\"Values\"]=1\n",
    "    else:\n",
    "        phi.loc[1,\"Values\"]=1\n",
    "    phi.loc[2,\"Values\"]=consumer_analysis.loc[i,\"Age\"]\n",
    "    if(consumer_analysis.loc[i, \"Ever_Married\"]==\"Yes\"):\n",
    "        phi.loc[3,\"Values\"]=1\n",
    "    phi.loc[4,\"Values\"]=consumer_analysis.loc[i,\"Family_Size\"]\n",
    "    for j in range(5,14):\n",
    "        if(phi.loc[j,\"Features\"]==consumer_analysis.loc[i,\"Profession\"]):\n",
    "            phi.loc[j,\"Values\"]=1\n",
    "    if(consumer_analysis.loc[i, \"Graduated\"]==\"Yes\"):\n",
    "        phi.loc[14,\"Values\"]=1\n",
    "    phi.loc[15, \"Values\"]=consumer_analysis.loc[i,\"Work_Experience\"]\n",
    "    for j in range(16,19):\n",
    "        if(phi.loc[j,\"Features\"]==consumer_analysis.loc[i,\"Energy_Consumption\"]):\n",
    "            phi.loc[j,\"Values\"]=1\n",
    "    for j in range(19,26):\n",
    "        if(phi.loc[j,\"Features\"]==consumer_analysis.loc[i,\"Preferred_Renewable\"]):\n",
    "            phi.loc[j,\"Values\"]=1\n",
    "    phi1=phi[\"Values\"].values\n",
    "    return phi1\n",
    "def one_hot_encode(group):\n",
    "    mapping = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "    encoded = np.zeros(4)\n",
    "    encoded[mapping[group]] = 1\n",
    "    return encoded\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Initialization of weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = len(feature_vector)\n",
    "num_classes = 4\n",
    "weight = np.zeros((num_classes, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Stochastic Gradient Descent using the first 5000 data, leaving the rest for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,11):\n",
    "    for i in consumer_analysis.head(5000).index:\n",
    "        y_i = one_hot_encode(consumer_analysis.loc[i, \"Group\"])\n",
    "        score = np.dot(weight, phix(i))\n",
    "        exp_score = np.exp(score - np.max(score))  \n",
    "        probabilities = exp_score / np.sum(exp_score)\n",
    "        error = probabilities - y_i\n",
    "        grad = np.outer(error, phix(i))\n",
    "        weight=weight - grad*0.1/(k)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Making a list of assigned group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "group_labels=[\"A\",\"B\",\"C\",\"D\"]\n",
    "for i in consumer_analysis.tail(1000).index:\n",
    "    score = np.dot(weight, phix(i))\n",
    "    exp_score = np.exp(score - np.max(score))  \n",
    "    probabilities = exp_score / np.sum(exp_score)\n",
    "    assigned_class_index = np.argmax(probabilities)\n",
    "    assigned_group = group_labels[assigned_class_index]\n",
    "    predictions.append(assigned_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Following cells contain code for checking the accuracy and precision of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_numerical_labels = [group_labels.index(label) for label in predictions]\n",
    "true_numerical_labels = [group_labels.index(label) for label in consumer_analysis.tail(1000)[\"Group\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.409\n",
      "0.39512777203301824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "accuracy = accuracy_score(true_numerical_labels, predicted_numerical_labels)\n",
    "precision = precision_score(true_numerical_labels, predicted_numerical_labels, average='weighted')\n",
    "print(accuracy)\n",
    "print(precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Assigning Group label to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_test_data[\"Group\"]=\"None\"\n",
    "for i in consumer_test_data.index:\n",
    "    score = np.dot(weight, phix(i))\n",
    "    exp_score = np.exp(score - np.max(score))  \n",
    "    probabilities = exp_score / np.sum(exp_score)\n",
    "    assigned_class_index = np.argmax(probabilities)\n",
    "    assigned_group = group_labels[assigned_class_index]\n",
    "    consumer_test_data.loc[i,\"Group\"]=assigned_group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
